# ğŸ¢ ArcGIS Enterprise RAG Chatbot

An **advanced Retrieval-Augmented Generation (RAG)** chatbot that helps users with ArcGIS Enterprise configuration, deployment, and raster analytics questions. Features intelligent two-step AI processing, transparent reasoning display, and lightning-fast responses.

![Python](https://img.shields.io/badge/python-v3.10+-blue.svg)
![FastAPI](https://img.shields.io/badge/FastAPI-0.100+-green.svg)
![LM Studio](https://img.shields.io/badge/LM%20Studio-Local%20AI-orange.svg)
![License](https://img.shields.io/badge/license-MIT-blue.svg)

## ğŸ¯ **Features**

- ğŸ§  **Dual-AI Processing**: DeepSeek-R1 for reasoning + Granite for formatting
- ğŸ’­ **Transparent Reasoning**: See how the AI thinks through problems
- ğŸ¨ **ChatGPT-Style Interface**: Live typing effect with optimized speed
- ğŸ” **Smart Context Filtering**: Similarity scoring prevents irrelevant responses
- ğŸ“š **Comprehensive Knowledge**: ArcGIS Enterprise documentation corpus
- ğŸš€ **All-in-One Server**: Single FastAPI server handles everything
- ğŸ’¾ **Privacy-First**: 100% local processing - no cloud dependencies
- âš¡ **Performance Optimized**: Intelligent model switching and caching

## ğŸ—ï¸ **Advanced Architecture**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Web Browser       â”‚â—„â”€â”€â–ºâ”‚   FastAPI Server     â”‚â—„â”€â”€â–ºâ”‚   LM Studio Hub     â”‚
â”‚                     â”‚    â”‚                      â”‚    â”‚                     â”‚
â”‚  - Chat Interface   â”‚    â”‚  - Static Files      â”‚    â”‚  ğŸ§  DeepSeek-R1      â”‚
â”‚  - Reasoning Toggle â”‚    â”‚  - RAG Pipeline      â”‚    â”‚  ğŸ“ Granite-3.1     â”‚
â”‚  - Live Typing      â”‚    â”‚  - Smart Routing     â”‚    â”‚  ğŸ” Nomic Embed     â”‚
â”‚  - Markdown Display â”‚    â”‚  - Context Filter    â”‚    â”‚                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
                                      â–¼
                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                           â”‚     ChromaDB         â”‚
                           â”‚                      â”‚
                           â”‚  - Vector Storage    â”‚
                           â”‚  - Similarity Search â”‚
                           â”‚  - Document Chunks   â”‚
                           â”‚  - Score Filtering   â”‚
                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ”„ Processing Flow:
Question â†’ Similarity Search â†’ Context Filter â†’ DeepSeek Reasoning â†’
Granite Formatting (if needed) â†’ Frontend Display with Reasoning
```

## ğŸ“‹ **Prerequisites**

### Required Software

- **Python 3.10+**
- **LM Studio** ([Download](https://lmstudio.ai/))

### Required Models in LM Studio

1. **Chat Model**: `phi-4-mini-reasoning-mlx` (or `deepseek-r1-distill-qwen-7b`)
2. **Embedding Model**: `text-embedding-nomic-embed-text-v1.5`

## ğŸš€ **Quick Start**

### 1. Clone & Setup

```bash
# Clone the project
git clone <repository-url>
cd rag_local

# Install dependencies
pip install -r requirements.txt
```

### 2. Setup LM Studio

1. **Download and install** [LM Studio](https://lmstudio.ai/)
2. **Load models**:
   - Chat: `phi-4-mini-reasoning-mlx`
   - Embeddings: `text-embedding-nomic-embed-text-v1.5`
3. **Start local server** on `127.0.0.1:1234`

### 3. Run the Application

```bash
# Start the server
uvicorn rag_api:app --reload --host 127.0.0.1 --port 8000

# Open your browser
open http://127.0.0.1:8000
```

## ğŸ“ **Project Structure**

```
rag_local/
â”œâ”€â”€ README.md                 # This file
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ main.py                  # Web crawler & data ingestion
â”œâ”€â”€ rag_api.py              # FastAPI server (backend + frontend)
â”œâ”€â”€ visited.txt             # Crawled URLs tracking
â”œâ”€â”€ static/
â”‚   â””â”€â”€ index.html          # Chatbot web interface
â””â”€â”€ chroma_data/            # ChromaDB vector database
    â”œâ”€â”€ chroma.sqlite3      # SQLite database
    â””â”€â”€ [uuid]/            # Vector embeddings
```

## ğŸ”§ **Configuration**

### Environment Variables

```bash
# Optional: Set user agent for web crawling
export USER_AGENT="hackathon-ragbot/0.1"
```

### Model Configuration

Edit `rag_api.py` to change models:

```python
# Chat model (line 62)
"model": "phi-4-mini-reasoning-mlx"

# Embedding model (line 33)
"model": "text-embedding-nomic-embed-text-v1.5"
```

### LM Studio Settings

- **Host**: `127.0.0.1`
- **Port**: `1234`
- **Endpoints**:
  - Chat: `/v1/chat/completions`
  - Embeddings: `/v1/embeddings`

## ğŸ“š **Usage**

### Web Interface

1. **Open browser**: Go to `http://127.0.0.1:8000`
2. **Ask questions**: Type ArcGIS Enterprise questions
3. **Get answers**: Receive AI-powered responses with context

### Example Questions

- "What is ArcGIS Enterprise?"
- "How do I configure raster analytics?"
- "What are the system requirements for deployment?"
- "How do I set up the web adaptor?"
- "How do I troubleshoot HTTPS connections?"

### API Endpoint

```bash
# Direct API call
curl -X POST http://127.0.0.1:8000/query \
  -H "Content-Type: application/json" \
  -d '{"question": "What is ArcGIS Enterprise?"}'
```

## ğŸ”„ **Data Management**

### Adding New Documentation

1. **Update URLs** in `main.py`:

   ```python
   crawl_and_store(["https://new-documentation-url.com"])
   ```

2. **Run crawler**:

   ```bash
   python main.py
   ```

3. **Restart server** to load new data

### Reset Database

```bash
# Remove existing data
rm -rf chroma_data/
rm visited.txt

# Re-run crawler
python main.py
```

## ğŸ› ï¸ **Development**

### Install Development Dependencies

```bash
pip install -r requirements.txt
```

### Running in Development Mode

```bash
# Auto-reload on changes
uvicorn rag_api:app --reload --host 127.0.0.1 --port 8000
```

### Debugging

- **Backend logs**: Check terminal running uvicorn
- **Frontend logs**: Browser Console (F12)
- **API testing**: Use `/docs` endpoint for Swagger UI

## ğŸ› **Troubleshooting**

### Common Issues

#### "ModuleNotFoundError: No module named 'langchain_chroma'"

```bash
pip install -U langchain-chroma
```

#### "Cannot connect to LM Studio"

- âœ… Ensure LM Studio is running
- âœ… Check models are loaded
- âœ… Verify server is on `127.0.0.1:1234`
- âœ… Test with curl:
  ```bash
  curl http://127.0.0.1:1234/v1/models
  ```

#### "405 Method Not Allowed"

- âœ… Restart FastAPI server
- âœ… Check `/docs` endpoint
- âœ… Verify CORS configuration

#### "Empty embeddings error"

- âœ… Check embedding model is loaded in LM Studio
- âœ… Verify API endpoint responds:
  ```bash
  curl http://127.0.0.1:1234/v1/embeddings \
    -H "Content-Type: application/json" \
    -d '{"model": "text-embedding-nomic-embed-text-v1.5", "input": "test"}'
  ```

#### Web interface not loading

- âœ… Ensure server is running on port 8000
- âœ… Check static files exist in `static/` directory
- âœ… Try direct URL: `http://127.0.0.1:8000/static/index.html`

## ğŸ“¦ **Dependencies**

### Core Libraries

- **FastAPI**: Web framework and API server
- **langchain-chroma**: Vector database integration
- **chromadb**: Vector storage and similarity search
- **beautifulsoup4**: HTML parsing for web crawling
- **requests**: HTTP client for API calls
- **tldextract**: Domain extraction for URL filtering

### Frontend Libraries (CDN)

- **Marked.js**: Markdown rendering
- **Modern CSS**: Responsive design with animations

## ğŸ” **Security & Privacy**

- âœ… **Local Processing**: All data stays on your machine
- âœ… **No Cloud APIs**: Uses local LM Studio models
- âœ… **CORS Configured**: Secure cross-origin requests
- âœ… **Input Validation**: Sanitized user inputs
- âœ… **Error Handling**: Safe error responses

## ğŸ“„ **License**

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ¤ **Contributing**

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add some amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ™‹â€â™‚ï¸ **Support**

If you encounter any issues:

1. **Check logs** in terminal and browser console
2. **Verify LM Studio** is running with correct models
3. **Test API endpoints** directly with curl
4. **Review troubleshooting** section above

## ğŸ”® **Future Enhancements**

- [ ] **Multi-language support**
- [ ] **Document upload interface**
- [ ] **Chat history persistence**
- [ ] **Advanced search filters**
- [ ] **Export conversation feature**
- [ ] **Model switching in UI**
- [ ] **Authentication system**
- [ ] **API rate limiting**

---

**Happy chatting with your ArcGIS Enterprise assistant! ğŸš€**
